{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import seaborn and apply its plotting styles\n",
    "import seaborn as sns\n",
    "sns.set(font_scale=2, style=\"white\")\n",
    "\n",
    "# import matplotlib\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.style as style\n",
    "import matplotlib.patches as mpatches\n",
    "# set plotting size parameter\n",
    "plt.rcParams['figure.figsize'] = (17, 7)\n",
    "\n",
    "# import pandas & numpy library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Statmodels & patsy\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Clean Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop/rename and create columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('164_data.csv')\n",
    "\n",
    "# Drop and rename columns\n",
    "data = data.drop(labels = ['EndDate', 'SC0', 'SC3', 'Duration (in seconds)', 'Status', 'IPAddress', 'Progress', \n",
    "        'Finished', 'RecordedDate', 'ResponseId',\n",
    "        'RecipientLastName', 'RecipientFirstName', 'RecipientEmail',\n",
    "        'ExternalReference', 'LocationLatitude', 'LocationLongitude',\n",
    "        'DistributionChannel', 'UserLanguage', 'Q9',\n",
    "        'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q20',\n",
    "        'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28', 'Q29',\n",
    "        'Q32_1', 'Q32_2', 'Q32_3',\n",
    "        'Q32_4', 'Q32_5', 'Q32_6', 'Q32_7', 'Q32_8', 'Q32_9', 'Q32_10',\n",
    "        'Q32_11', 'Q32_12', 'Q32_13', 'Q32_14', 'Q32_15', 'Q32_16'], axis=1)\n",
    "\n",
    "data.columns = ['StartDate', 'Q_Eat', 'Q_Sleep', 'Q_Comfort', 'Q_Exercise',\n",
    "       'C_First Click', 'C_Last Click', 'C_Page Submit',\n",
    "       'C_Click Count', 'E_First Click', 'E_Last Click',\n",
    "       'E_Page Submit', 'E_Click Count',\n",
    "       'Q_Age', 'Q_Gender', 'Q_Ethn', 'Q_Income', 'Q_FinSec', 'PSS',\n",
    "       'Worry', 'IM', 'IR', 'ER', 'AM', 'KeyResponses', 'PlayerScore']\n",
    "\n",
    "data = data.iloc[1:]\n",
    "\n",
    "# Add column describing experimental/control group\n",
    "data = data.assign(Group= data['C_Page Submit'].isna().apply(lambda x: 'Experimental' if x == True else 'Control'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine column repeats\n",
    "def combine_CE(data):\n",
    "    CE_cols = np.unique([col[1] for col in data.columns.str.split('_') if col[0] in ['C', 'E']])\n",
    "    for label in CE_cols:\n",
    "        C_col = f\"C_{label}\"\n",
    "        E_col = f\"E_{label}\"\n",
    "        if C_col in data.columns and E_col in data.columns:\n",
    "            data = data.assign(**{label: data[C_col].fillna(data[E_col])})\n",
    "            data = data.drop(labels= [C_col, E_col], axis=1)\n",
    "\n",
    "    return data\n",
    "\n",
    "data = combine_CE(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract demographic information since it's not being included in any analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into data for analysis and demographic information\n",
    "demographic_info = data[['Q_Age', 'Q_Gender', 'Q_Ethn', 'Q_Income', 'Q_FinSec']]\n",
    "data = data[data.columns.difference(['Q_Age', 'Q_Gender', 'Q_Ethn', 'Q_Income', 'Q_FinSec'])].drop(labels= ['First Click', 'Last Click'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covert numeric columns to floats, add SDI column, and reorder columns/add multi-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numeric columns to floats for handling\n",
    "def float_convert(value):\n",
    "    try:\n",
    "        return float(value)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "num_cols = ['PSS', 'Worry', 'IM', 'IR', 'ER', 'AM', 'PlayerScore', 'Page Submit']\n",
    "for col in num_cols:\n",
    "    data[col] = data[col].apply(float_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for self-determination scale based on the formula\n",
    "data = data.assign(SDI= 2*data[\"IM\"]+data[\"IR\"]-data[\"ER\"]-2*data[\"AM\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns for salience and create multi-index\n",
    "data = data[['StartDate', 'Group', 'Page Submit', 'PlayerScore', 'Worry', 'PSS', 'SDI', 'IM', 'IR', 'ER', 'AM',\n",
    "       'Q_Comfort', 'Q_Eat', 'Q_Exercise', 'Q_Sleep', 'Click Count', 'KeyResponses']]\n",
    "\n",
    "multi_index = [\n",
    "    ('Metadata', 'StartDate'),\n",
    "    ('Metadata', 'Group'),\n",
    "    ('Task', 'Page Submit'),\n",
    "    ('Task', 'PlayerScore'),\n",
    "    ('Psych', 'Worry'),\n",
    "    ('Psych', 'PSS'),\n",
    "    ('SIMS', 'SDI'),\n",
    "    ('SIMS', 'IM'),\n",
    "    ('SIMS', 'IR'),\n",
    "    ('SIMS', 'ER'),\n",
    "    ('SIMS', 'AM'),\n",
    "    ('Questions', 'Comfort'),\n",
    "    ('Questions', 'Eat'),\n",
    "    ('Questions', 'Exercise'),\n",
    "    ('Questions', 'Sleep'),\n",
    "    ('Interactions', 'Click Count'),\n",
    "    ('Interactions', 'KeyResponses')\n",
    "]\n",
    "\n",
    "# Assign MultiIndex to DataFrame columns\n",
    "data.columns = pd.MultiIndex.from_tuples(multi_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows will null values\n",
    "data = data[data[['Task', 'Psych', 'SIMS']].isna().any(axis=1) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert body state information to make it more readable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for coverting comfort column into numeric values (Scale: -2 --> 2)\n",
    "def convert_comfort(input):\n",
    "    output = 0\n",
    "    if \"Very\" in input:\n",
    "        output = 2\n",
    "    elif \"Somewhat\" in input:\n",
    "        output = 1\n",
    "    else:\n",
    "        output = 0\n",
    "    \n",
    "    if \"uncomfortable\" in input:\n",
    "        output *= -1\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_hrs(input):\n",
    "    output = input.replace('hours', 'hrs')\n",
    "    output = output.replace('< ', '0-')\n",
    "    output = output.replace('≤ ', '0-')\n",
    "    output = output.replace('≥ ', '')\n",
    "    if '8 ' in output:\n",
    "        output = output.replace('8', '8+')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'int' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Convert all columns in Questions to more readable format\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39massign(Comfort\u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mQuestions\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mComfort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_comfort\u001b[49m\u001b[43m)\u001b[49m, \n\u001b[1;32m      3\u001b[0m     Eat\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEat\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(convert_hrs), Sleep\u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSleep\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(convert_hrs))\n\u001b[1;32m      4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExercise\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQuestions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExercise\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;28mstr\u001b[39m: \u001b[38;5;28mstr\u001b[39m\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdays per week\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124md/wk\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:4539\u001b[0m, in \u001b[0;36mSeries.map\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\n\u001b[1;32m   4461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4462\u001b[0m     arg: Callable \u001b[38;5;241m|\u001b[39m Mapping \u001b[38;5;241m|\u001b[39m Series,\n\u001b[1;32m   4463\u001b[0m     na_action: Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   4464\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m   4465\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4466\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[1;32m   4467\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4537\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[1;32m   4538\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4539\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4540\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   4541\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4542\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/base.py:890\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    889\u001b[0m \u001b[38;5;66;03m# mapper is a function\u001b[39;00m\n\u001b[0;32m--> 890\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mmap_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/_libs/lib.pyx:2924\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mconvert_comfort\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert_comfort\u001b[39m(\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m      3\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mVery\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m:\n\u001b[1;32m      5\u001b[0m         output \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSomewhat\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28minput\u001b[39m:\n",
      "\u001b[0;31mTypeError\u001b[0m: argument of type 'int' is not iterable"
     ]
    }
   ],
   "source": [
    "# Convert all columns in Questions to more readable format\n",
    "data['Questions'] = data['Questions'].assign(Comfort= data['Questions', 'Comfort'].map(convert_comfort), \n",
    "    Eat= data['Questions', 'Eat'].map(convert_hrs), Sleep= data['Questions', 'Sleep'].map(convert_hrs))\n",
    "data['Questions', 'Exercise'] = data['Questions', 'Exercise'].apply(lambda str: str.replace('days per week', 'd/wk'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Questions', 'Sleep'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Questions', 'Eat'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data after cleaning\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate data into two data frames:** Control and Experimental\n",
    "- *(makes some functions easier, but these dataframes will not always be used)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two dataframes: separate data from each group\n",
    "E_data = data[data['Metadata','Group'] == 'Experimental']\n",
    "C_data = data[data['Metadata','Group'] == 'Control']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Plotting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributions of numeric variables\n",
    "\n",
    "*For measures that are taken before the task commences (PSS and Worry), these distributions should look relatively simiar between groups.\n",
    "All other distributions might be affected by group*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of all numeric variables between groups\n",
    "def btwn_groups_plots(data, subplots, fig_size):\n",
    "    v, h = subplots[:2]\n",
    "    fig, axes = plt.subplots(v, h, figsize=fig_size)\n",
    "    label_size =12\n",
    "    i = 0\n",
    "\n",
    "    if v * h == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "    \n",
    "    # Use second level of multi-index to index columns for plotting\n",
    "    data2 = data.droplevel(level=0, axis=1)\n",
    "\n",
    "    # Only plot numeric columns\n",
    "    for col in data[['Task', 'Psych', 'SIMS']].columns.get_level_values(1):\n",
    "        sns.histplot(data= data2, x= col, ax=axes[i], hue= 'Group', kde= True, common_norm= True)\n",
    "        axes[i].set_title(col, fontsize=label_size)\n",
    "        axes[i].set_xlabel(col, fontsize=label_size)\n",
    "        axes[i].set_ylabel('Density', fontsize=label_size)\n",
    "        axes[i].tick_params(axis=\"both\", labelsize=label_size)\n",
    "        i += 1\n",
    "\n",
    "    fig.delaxes(axes[-1])\n",
    "    plt.tight_layout()\n",
    "\n",
    "btwn_groups_plots(data, [len(num_cols)//2+1, 2, 1], [15, 25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scatterplots of numeric variables vs. PlayerScore and Page Submit (quitting time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions relationships of all numeric variable to task score and quitting time\n",
    "def within_groups_plots(data, subplots, fig_size):\n",
    "    v, h = subplots[:2]\n",
    "    fig, axes = plt.subplots(v, h, figsize=fig_size)\n",
    "    label_size = 9\n",
    "    i = 0\n",
    "\n",
    "    if v * h == 1:\n",
    "        axes = [axes]  # Convert single-axis to a list\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    data2 = data.droplevel(level=0, axis=1)\n",
    "    for y_col in data['Task'].columns:\n",
    "        for x_col in data[['Psych', 'SIMS']].columns.get_level_values(1):\n",
    "            sns.scatterplot(data= data2, x= x_col, y= y_col, hue= \"Group\", ax=axes[i])\n",
    "            axes[i].set_title(f\"{y_col} vs. {x_col}\", fontsize=label_size)\n",
    "            axes[i].set_xlabel(x_col, fontsize=label_size)\n",
    "            axes[i].set_ylabel(y_col, fontsize=label_size)\n",
    "            axes[i].tick_params(axis=\"both\", labelsize=label_size)\n",
    "            axes[i].legend(fontsize= label_size)\n",
    "            i += 1\n",
    "\n",
    "    if len(subplots) == 3:\n",
    "        extra_axes = v * h - i\n",
    "        for j in range(extra_axes):\n",
    "            plt.delaxes(axes[i + j])\n",
    "            \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot experimental group data\n",
    "within_groups_plots(data, [4, 4, 1], [15, 12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score/Quitting Time Distribution Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of player score between groups\n",
    "plt.figure(figsize= (15,5))\n",
    "sns.boxplot(data=data.droplevel(level=0, axis=1), x=\"PlayerScore\", hue=\"Group\")\n",
    "plt.title(\"Distribution of PlayerScore\")\n",
    "plt.legend(loc= \"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of quitting time between groups\n",
    "plt.figure(figsize= (15,5))\n",
    "sns.boxplot(data=data.droplevel(level=0, axis=1), x=\"Page Submit\", hue=\"Group\")\n",
    "plt.title(\"Distribution of Submission Time\")\n",
    "plt.legend(loc= \"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Spearman's Coefficients and Correlations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spearman's Rank Correlation Coefficients: describe the correlation of numeric variables to score and quitting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate spearman correlations between variables\n",
    "spearman_E = E_data.droplevel(level=0, axis=1).corr(method= 'spearman').iloc[2:, :2]\n",
    "spearman_C = C_data.droplevel(level=0, axis=1).corr(method= 'spearman').iloc[2:, :2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental group correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's correlations for the experiemental group\n",
    "spearman_E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control group correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spearman's correlations for the control group\n",
    "spearman_C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot correlation coefficients to visualize which variables are most correlated to score/quitting time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation plot for quitting time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations to quitting time of all survey results\n",
    "C_bar = sns.barplot(data= spearman_C[\"Page Submit\"], color= 'red')\n",
    "C_patch = mpatches.Patch(color='red', label='Control')\n",
    "E_bar = sns.barplot(data= spearman_E[\"Page Submit\"], color= 'blue')\n",
    "E_patch = mpatches.Patch(color='blue', label='Experimental')\n",
    "plt.legend(handles= [C_patch, E_patch])\n",
    "plt.title(\"Spearman's Correlations to Page Submit\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.xlabel(\"Survey Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation plot for score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot correlations to score of all survey results\n",
    "C_bar = sns.barplot(data= spearman_C[\"PlayerScore\"], color= 'red')\n",
    "C_patch = mpatches.Patch(color='red', label='Control')\n",
    "E_bar = sns.barplot(data= spearman_E[\"PlayerScore\"], color= 'blue')\n",
    "E_patch = mpatches.Patch(color='blue', label='Experimental')\n",
    "plt.legend(handles= [C_patch, E_patch])\n",
    "plt.title(\"Spearman's Correlations to PlayerScore\")\n",
    "plt.ylabel(\"Correlation Coefficient\")\n",
    "plt.xlabel(\"Survey Score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P-values for correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to get p-values\n",
    "def get_pval(data, degrees_of_freedom, tails= \"two-sided\"):\n",
    "    tstat_df = data.apply(lambda r: r * np.sqrt(len(C_data) - 2) / np.sqrt(1 - r**2))\n",
    "    if tails == \"one-sided\":\n",
    "        pval_df = tstat_df.apply(lambda t: stats.t.cdf(t, degrees_of_freedom))\n",
    "    elif tails == \"two-sided\":\n",
    "        pval_df = tstat_df.apply(lambda t: 2 * (1 - stats.t.cdf(abs(t), degrees_of_freedom)))\n",
    "    else:\n",
    "        raise ValueError(\"tails must be defined\")\n",
    "    \n",
    "    return pval_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call get_pval function to create dataframes for the experiemental (E) and control (C) groups with significance of correlations\n",
    "C_pvalues_df = get_pval(spearman_C, len(C_data)-1)\n",
    "E_pvalues_df = get_pval(spearman_E, len(E_data)-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-values for the control group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at p-values for control\n",
    "C_pvalues_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-values for the experimental group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at p-values for experimental\n",
    "E_pvalues_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which p-values are significant for each group?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for printing which p-values are significant\n",
    "def significant_pval(data, group):\n",
    "    output = f\"{group}: Significant P-values\\n\\n\"\n",
    "    threshold = 0.05\n",
    "    sig_data = data.apply(lambda p: p <= threshold)\n",
    "    for row in data.index:\n",
    "        for col in data.columns:\n",
    "            if sig_data.loc[row, col] == True:\n",
    "                output += f\"{row} vs. {col}:\\t P-value: {data.loc[row, col]:10f}\\n\"\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(significant_pval(C_pvalues_df, \"Control\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(significant_pval(E_pvalues_df, \"Experimental\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mann-Whitney U Tests \n",
    "Testing significance of differences between groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U Tests for PlayerScore -- H1 : E > C\n",
    "score_u_stat, score_pval = stats.mannwhitneyu(np.array(E_data['Task', 'PlayerScore']), \n",
    "                                     np.array(C_data['Task', 'PlayerScore']), \n",
    "                                     method='exact', alternative='greater')\n",
    "print(f\"The p-value for the distribution of score between groups given H1 : E > C is\\t{score_pval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann-Whitney U Tests for Page Submit -- H1 : E > C\n",
    "submit_u_stat, submit_pval = stats.mannwhitneyu(np.array(E_data['Task', 'Page Submit']), \n",
    "                                     np.array(C_data['Task', 'Page Submit']), \n",
    "                                     method='exact', alternative='greater')\n",
    "print(f\"The p-value for the distribution of quitting time between groups given H1 : E > C is\\t{submit_pval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Body state distribution and relationships**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distribution for all body state information across groups (should resemble eachother)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bodystate(data, subplots, fig_size):\n",
    "    v, h = subplots[:2]\n",
    "    fig, axes = plt.subplots(v, h, figsize=fig_size)\n",
    "    label_size = 9\n",
    "    i = 0\n",
    "\n",
    "    if v * h == 1:\n",
    "        axes = [axes]  # Convert single-axis to a list\n",
    "    else:\n",
    "        axes = axes.flatten()\n",
    "\n",
    "    data2 = data.droplevel(level=0, axis=1)\n",
    "    for state in data['Questions'].columns:\n",
    "        sns.countplot(data= data2, x= state, hue= \"Group\", ax=axes[i], order= data2[state].unique())\n",
    "        axes[i].set_title(f\"{state} Plot\", fontsize=label_size)\n",
    "        axes[i].set_xlabel(state, fontsize=label_size)\n",
    "        axes[i].set_ylabel(\"Density\", fontsize=label_size)\n",
    "        axes[i].tick_params(axis=\"both\", labelsize=label_size)\n",
    "        axes[i].legend(fontsize= label_size)\n",
    "        i += 1\n",
    "\n",
    "    if len(subplots) == 3:\n",
    "        extra_axes = v * h - i\n",
    "        for j in range(extra_axes):\n",
    "            plt.delaxes(axes[i + j])\n",
    "            \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data['Questions', 'Sleep'].unique()\n",
    "a.sort()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_bodystate(data, [2, 2], (12, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Demographic Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender\n",
    "labelsize = 9\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(demographic_info[\"Q_Gender\"].value_counts(), labels= demographic_info[\"Q_Gender\"].value_counts().index, startangle=180, autopct='%1.1f%%', textprops= {\"fontsize\": 10})\n",
    "ax.set_title(\"Participant Gender\", fontsize= labelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age\n",
    "labelsize = 9\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(demographic_info[\"Q_Age\"].value_counts(), labels= demographic_info[\"Q_Age\"].value_counts().index, startangle=180, autopct='%1.1f%%', textprops= {\"fontsize\": 10})\n",
    "ax.set_title(\"Participant Age\", fontsize= labelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ethnicity\n",
    "labelsize = 9\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(demographic_info[\"Q_Ethn\"].value_counts(), labels= demographic_info[\"Q_Ethn\"].value_counts().index, startangle=180, autopct='%1.1f%%', textprops= {\"fontsize\": 10})\n",
    "ax.set_title(\"Participant Ethnicity\", fontsize= labelsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Income\n",
    "labelsize = 9\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(demographic_info[\"Q_Income\"].value_counts(), labels= demographic_info[\"Q_Income\"].value_counts().index, startangle=180, autopct='%1.1f%%', textprops= {\"fontsize\": 10})\n",
    "ax.set_title(\"Participant Income\", fontsize= labelsize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
